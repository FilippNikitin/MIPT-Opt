{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Семинар 16\n",
    "# Задача наименьших квадратов (Least Squares Problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Постановка задачи\n",
    "\n",
    "1. **Широкая:** пусть даны $m$ пар измерениий $(x_i, y_i)$, где $ x_i \\in \\mathbb{R}^n, \\; y_i \\in \\mathbb{R}^p$. Найти такую функцию $f$ что \n",
    "$$\n",
    "\\frac{1}{2}\\|f(x_i) - y_i \\|^2_2 \\to \\min\n",
    "$$\n",
    "\n",
    "2. **Уже:** пусть даны $m$ пар измерениий $(x_i, y_i)$, где $ x_i \\in \\mathbb{R}^n, \\; y_i \\in \\mathbb{R}^p$. Найти такую *параметрическую* функцию $f(x, w)$ что \n",
    "$$\n",
    "\\frac{1}{2}\\|f(x_i, w) - y_i \\|^2_2 \\to \\min_w\n",
    "$$\n",
    "\n",
    "3. **Ещё уже:** пусть даны $m$ пар измерениий $(x_i, y_i)$, где $ x_i \\in \\mathbb{R}^n, \\; y_i \\in \\mathbb{R}$. Найти такую *параметрическую* функцию $f(x, w)$ что \n",
    "$$\n",
    "\\frac{1}{2} \\sum_{i=1}^m(f(x_i, w) - y_i )^2 \\to \\min_w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Линейный случай\n",
    "\n",
    "Рассмотрим случай линейной зависимости между измерениями $x_i \\in \\mathbb{R}^n$ и $y_i \\in \\mathbb{R}, \\; i = 1,\\ldots, m$.\n",
    "\n",
    "Тогда\n",
    "$$\n",
    "f(x, w) = x^{\\top}w\n",
    "$$\n",
    "или\n",
    "$$\n",
    "f(X, W) = XW\n",
    "$$\n",
    "Задача наименьших квадратов формулируется в виде\n",
    "$$\n",
    "L(w|X, y) = \\frac{1}{2}\\sum\\limits_{i=1}^m (x^{\\top}_i w - y_i)^2 = \\frac{1}{2}\\|Xw - y \\|^2_2 \\to \\min_w\n",
    "$$\n",
    "\n",
    "**Замечание.** Везде далее $m \\geq n$ и $\\mathrm{rank}(X) = n$ кроме специально оговоренных случаев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Нормальное уравнение\n",
    "\n",
    "Из необходимого условия минимума первого порядка и выпуклости нормы следует, что \n",
    "$$\n",
    "L'(w^* | X, y) = 0 \\Rightarrow (X^{\\top}X)w^* = X^{\\top}y\n",
    "$$\n",
    "\n",
    "**Замечение:** убедитесь, что Вы можете вывести выражение для $w^*$!\n",
    "\n",
    "**Вопрос:** к какой задаче сведена задача оптимизации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Прямые методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Разложение Холецкого\n",
    "\n",
    "**Определение.** Любая матрица $A \\in \\mathbb{S}^n_{++}$ имеет единственное разложение Холецкого:\n",
    "$$\n",
    "A = LL^{\\top},\n",
    "$$\n",
    "где $L$ - нижнетреугольная матрица.\n",
    "\n",
    "Алгоритм:\n",
    "1. Вычислить $X^{\\top}X$ и $X^{\\top}y$\n",
    "2. Вычислить разложение Холецкого матрицы $X^{\\top}X$\n",
    "3. Найти $w^*$ прямой и обратной подстановкой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pro & contra\n",
    "\n",
    "Pro \n",
    "\n",
    "- при $m \\gg n$ хранение $X^{\\top}X$ требует намного меньше памяти, чем хранение $X$\n",
    "- если матрица $X$ разреженная, существуют методы также дающие разреженное разложение Холецкого \n",
    "\n",
    "Contra\n",
    "\n",
    "- число обусловленности $X^{\\top}X$ равно квадрату числа обусловленности $X$. Ошибка пропорциональна обусловленности.\n",
    "- необходимо вычислить $X^{\\top}X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### QR разложение\n",
    "\n",
    "**Определение.** Любую матрицу $A \\in \\mathbb{R}^{m \\times n}$ можно представить в виде\n",
    "$$\n",
    "A = QR,\n",
    "$$\n",
    "где $Q \\in \\mathbb{R}^{m \\times m}$ - унитарная матрица, а $R \\in \\mathbb{R}^{m \\times n}$ - прямоугольная верхнетреугольная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Применение\n",
    "\n",
    "1. Вычислить QR разложение матрицы $X$: $X = QR$.\n",
    "2. $Q = [Q_1, Q_2]$, $Q_1 \\in \\mathbb{R}^{m \\times n}$,\n",
    "$R = \n",
    "\\begin{bmatrix}\n",
    "R_1\\\\\n",
    "0\n",
    "\\end{bmatrix}$,\n",
    "$R_1 \\in \\mathbb{R}^{n \\times n}$ - квадратная верхнетреугольная матрица\n",
    "2. Задача примет вид: \n",
    "$$\n",
    "\\|R_1w - Q_1^{\\top}y \\|^2_2 \\to \\min_w\n",
    "$$\n",
    "и нормальное уравнение\n",
    "$$\n",
    "R_1w^* = Q_1^{\\top}y\n",
    "$$\n",
    "Получили уравнение с квадратной верхнетреугольной матрицей, которое легко решается обратной подстановкой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pro & contra\n",
    "\n",
    "Pro \n",
    "\n",
    "- ошибка пропорциональна числу обусловленности $X$, а не $X^{\\top}X$\n",
    "- более устойчив, чем использование разложение Холецкого\n",
    "\n",
    "Contra\n",
    "\n",
    "- нельзя контролировать устойчивость решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Сингулярное разложение (SVD)\n",
    "\n",
    "**Определение.** Любую матрицу $A \\in \\mathbb{R}^{m \\times n}$ можно представить в виде\n",
    "$$\n",
    "A = U\\widehat{\\Sigma} V^* = [U_1, U_2] \\begin{bmatrix} \\Sigma\\\\ 0 \\end{bmatrix} V^*,\n",
    "$$\n",
    "где $U \\in \\mathbb{R}^{m \\times m}$ - унитарная матрица, $U_1 \\in \\mathbb{R}^{m \\times n}$, $\\Sigma = \\mathrm{diag}(\\sigma_1, \\ldots, \\sigma_n) \\in \\mathbb{R}^{n \\times n}$ - диагональная с сингулярными числами $\\sigma_i$ на диагонали, и $V \\in \\mathbb{R}^{n \\times n}$ - унитарная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Применение\n",
    "\n",
    "$$\n",
    "\\| Xw - y\\|^2_2 = \\left\\| \\begin{bmatrix} \\Sigma \\\\ 0 \\end{bmatrix} V^* w - \\begin{bmatrix} U_1^{\\top} \\\\ U_2^{\\top} \\end{bmatrix}y \\right\\|^2_2 \\sim \\| \\Sigma V^* w - U_1^{\\top}y \\|^2_2\n",
    "$$\n",
    "Решение линейной системы с **квадратной** матрицей:\n",
    "$$\n",
    "w^* = V\\Sigma^{-1}U_1^{\\top}y = \\sum\\limits_{i=1}^n \\frac{u_i^{\\top}y}{\\sigma_i} v_i,\n",
    "$$\n",
    "где $v_i$ и $u_i$ - столбцы матриц $V$ и $U_1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pro & contra\n",
    "\n",
    "Pro \n",
    "\n",
    "- информация о чувствительности решения к возмущениям $y$\n",
    "- контроль устойчивости: малые сингулярные числа можно отбросить\n",
    "- если матрица близка к вырожденной, то только SVD позволяет это показать\n",
    "\n",
    "Contra\n",
    "\n",
    "- вычисление SVD наиболее затратно по сравнению с QR разложением и разложением Холецкого"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12070327686e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 10\n",
    "m = 2 * n\n",
    "X = np.random.randn(m, n)\n",
    "w = np.random.randn(n)\n",
    "y = X.dot(w) + 1e-5 * np.random.randn(m)\n",
    "\n",
    "w_est = np.linalg.solve(X.T.dot(X), X.T.dot(y))\n",
    "print np.linalg.norm(w - w_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as sclin\n",
    "\n",
    "def CholSolve(X, y):\n",
    "    res = sclin.cho_factor(X.T.dot(X), lower=True)\n",
    "    return sclin.cho_solve(res, X.T.dot(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12070327679e-05\n"
     ]
    }
   ],
   "source": [
    "w_chol = CholSolve(X, y)\n",
    "print np.linalg.norm(w - w_chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Нелинейный случай"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Метод Гаусса-Ньютона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Метод Левенберга-Марквардта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Некорректные задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Определение** (Ж. Адамар и урматы). Задача называется *некорректной*, если не выполняется хотя бы одно условие корректности задачи:\n",
    "\n",
    "1. Существование решения\n",
    "2. Единственность решения\n",
    "3. Непрерывная зависимость от внешних параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Регуляризация\n",
    "\n",
    "**Определение.** Регуляризацией называют процесс введения дополнительной информации в модель для решения некорректных задач.\n",
    "\n",
    "Примеры:\n",
    "- повысить устойчивость с помощью изменения целевой функции\n",
    "- сделать решение единственным, наложив ограничения\n",
    "- преобразовать целевую функцию, чтобы решение появилось или стало конечным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Тихоновская регуляризация (Ridge или $\\ell_2$ регуляризация)\n",
    "\n",
    "$$\n",
    "\\min_w \\|Xw - y \\|^2_2 + \\frac{\\alpha}{2}\\|w\\|^2_2, \\quad \\alpha > 0\n",
    "$$\n",
    "\n",
    "**Упражнение:** получите аналог нормального уравнения для такой задачи. Какая у модифицированного нормального уравнения интерпретация и почему такая регуляризация работает?\n",
    "\n",
    "**Алгоритмы** аналогичны линейному случаю без регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Lasso ($\\ell_1$ регуляризация)\n",
    "\n",
    "$$\n",
    "\\min_w \\|Xw - y \\|^2_2 + \\alpha\\|w\\|_1, \\quad \\alpha > 0\n",
    "$$\n",
    "\n",
    "Решение получают координатным спуском (буждет рассказан позднее)\n",
    "\n",
    "Особенности:\n",
    "- недифференцируемая, но выпуклая целевая функция\n",
    "- релаксация $\\ell_0$\n",
    "- разреженное решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Elastic Net\n",
    "\n",
    "$$\n",
    "\\min_w \\|Xw - y \\|^2_2 + \\alpha \\rho\\|w\\|_1 + \\alpha\\frac{1-\\rho}{2}\\| w \\|^2_2, \\quad \\rho \\in [0, 1], \\alpha > 0\n",
    "$$\n",
    "\n",
    "Особенности:\n",
    "- комбинация Lasso и Ridge\n",
    "- алгоритм - координатный спуск\n",
    "- более устойчиво, чем Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Резюме\n",
    "\n",
    "1. Задача наименьших квадратов\n",
    "2. Алгоритмы для линейного случая\n",
    "3. Алгоритмы для нелинейного случая\n",
    "4. Некорректные задачи и способы их решения"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cvxpy]",
   "language": "python",
   "name": "conda-env-cvxpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
