{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Семинар 13\n",
    "\n",
    "# Методы спуска (Descent methods). Градиентный спуск: насколько глубока кроличья нора? Дёшево и сердито"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## На прошлом семинаре...\n",
    "1. Введение в численные методы оптимизации\n",
    "2. Общая схема работы метода\n",
    "3. Как сравнивать методы оптимизации?\n",
    "4. Зоопарк задач и методов\n",
    "5. Одномерная минимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Что такое методы спуска?\n",
    "\n",
    "Последовательность $x_k$ генерируется по правилу\n",
    "$$\n",
    "x_{k+1} = x_k + \\alpha_k h_k\n",
    "$$\n",
    "так что\n",
    "$$\n",
    "f(x_{k+1}) < f(x_k)\n",
    "$$\n",
    "Направление $h_k$ называется *направлением убывания*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "def DescentMethod(f, x0, epsilon, **kwargs):\n",
    "    x = x0\n",
    "    while StopCriterion(x, f, **kwargs) > epsilon:\n",
    "        h = ComputeDescentDirection(x, f, **kwargs)\n",
    "        alpha = SelectStepSize(x, h, f, **kwargs)\n",
    "        x = x + alpha * h\n",
    "    return x\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Направление убывания\n",
    "Рассмотрим линейную аппроксимацию дифференцируемой функции $f$ вдоль некоторого направления убывания $h, \\|h\\|_2 = 1$:\n",
    "$$\n",
    "f(x + \\alpha h) = f(x) + \\alpha \\langle f'(x), h \\rangle + o(\\alpha)\n",
    "$$\n",
    "Из условия убывания\n",
    "$$\n",
    "f(x) + \\alpha \\langle f'(x), h \\rangle + o(\\alpha) < f(x)\n",
    "$$\n",
    "и переходя к пределу при $\\alpha \\rightarrow 0$:\n",
    "$$\n",
    "\\langle f'(x), h \\rangle \\leq 0\n",
    "$$\n",
    "Также из неравенства Коши-Буняковского-Шварца\n",
    "$$\n",
    "\\langle f'(x), h \\rangle \\geq -\\| f'(x) \\|_2 \\| h \\|_2 = -\\| f'(x) \\|_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Таким образом, направление антиградиента \n",
    "$$\n",
    "h = -\\dfrac{f'(x)}{\\|f'(x)\\|_2}\n",
    "$$\n",
    "даёт направление **наискорейшего локального** убывания функции$~f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Градиентный метод\n",
    "```python\n",
    "def GradientDescentMethod(f, x0, epsilon, **kwargs):\n",
    "    x = x0\n",
    "    while StopCriterion(x, f, **kwargs) > epsilon:\n",
    "        h = ComputeGradient(x, f, **kwargs)\n",
    "        alpha = SelectStepSize(x, h, f, **kwargs)\n",
    "        x = x - alpha * h\n",
    "    return x\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Как выбрать шаг $\\alpha_k$? (J. Nocedal, S. Wright Numerical Optimization, $\\S$ 3.1.)\n",
    "\n",
    "Список подходов:\n",
    "- Постоянный шаг \n",
    "$$\n",
    "\\alpha_k = \\overline{\\alpha}\n",
    "$$\n",
    "- Априорно заданная последовательность, например\n",
    "$$\n",
    "\\alpha_k = \\dfrac{\\overline{\\alpha}}{\\sqrt{k+1}}\n",
    "$$\n",
    "- Наискорейший спуск\n",
    "$$\n",
    "\\alpha_k = \\arg\\min_{\\alpha \\geq 0} f(x_k - \\alpha f'(x_k))\n",
    "$$\n",
    "- Требование **достаточного** убывания, требование **существенного** убывания и условие кривизны: для некоторых $\\beta_1, \\beta_2$, таких что $0 < \\beta_1 < \\beta_2 < 1$ найти $x_{k+1}$ такую что\n",
    "\n",
    "    - Достаточное убывание: $f(x_{k+1}) \\leq f(x_k) + \\beta_1 \\alpha_k \\langle f'(x_k), h_k \\rangle$\n",
    "    - Существенное убывание: $f(x_{k+1}) \\geq f(x_k) + \\beta_2 \\alpha_k \\langle f'(x_k), h_k \\rangle$\n",
    "    - Условие кривизны: $\\langle f'(x_{k+1}), h_k \\rangle \\geq \\beta_2 \\langle f'(x_k), h_k \\rangle$\n",
    "\n",
    "Обычно коэффициенты выбирают так: $\\beta_1 \\in (0, 0.1)$, а $\\beta_2 \\in (0.9, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Анализ и мотивация подходов к выбору шага $\\alpha_k$\n",
    "- Постоянный шаг: самое простое и неэффективное решение\n",
    "- Априорно заданная последовательность: немногим лучше постоянного шага\n",
    "- Наискорейший спуск: самое лучшее решение, но применимо только если вспомогательная задача решается аналитически или ооооооочень быстро. <br></br>\n",
    "То есть почти всегда неприменимо :)\n",
    "- Требование достаточного убывания, требование существенного убывания и условие кривизны:\n",
    "    - требование достаточного убывания гарантирует, что функция в точке $x_{k+1}$ не превосходит линейной аппроксимации с коэффициентом наклона $\\beta_1$\n",
    "    - требование существенного убывания гарантирует, что функция в точке $x_{k+1}$ убывает не меньше, чем линейная аппроксимация c коэффициентом наклона $\\beta_2$\n",
    "    - условие кривизны гарантирует, что угол наклона касательной в точке $x_{k+1}$ не меньше, чем угол наклона касательной в точке $x_k$, <br></br>\n",
    "умноженный на $\\beta_2$ \n",
    "\n",
    "Требование существенного убывания и условие кривизны обеспечивают убывание функции по выбранному направлению $h_k$. Обычно выбирают одно из них.\n",
    "[comment]: <> (<img src=\"Goldstein.png\", style=\"width: 600px;\">)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Альтернативные названия\n",
    "- Требование достаточного убывания $\\equiv$ правило Армихо\n",
    "- Требование достаточного убывания + условие кривизны $\\equiv$ правило Вольфа\n",
    "- Требование достаточного убывания + требование существенного убывания $\\equiv$ правило Гольдштейна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backtracking \n",
    "\n",
    "```python\n",
    "def SelectStepSize(x, f, h, rho, alpha0, beta1, beta2):\n",
    "    # 0 < rho < 1\n",
    "    # alpha0 - initial guess of step size\n",
    "    # beta1 and beta2 - constants from conditions\n",
    "    alpha = alpha0\n",
    "    # Check violoting sufficient decrease and curvature conditions \n",
    "    while (f(x - alpha * h) >= f(x) + beta1 * alpha grad_f(x_k).dot(h)) and \n",
    "          (grad_f(x - alpha * h).dot(h) <= beta2 * grad_f(x_k).dot(h)):\n",
    "        alpha *= rho\n",
    "    return alpha\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Теоремы сходимости (Б.Т. Поляк Введение в оптимизацию, гл. 1, $\\S$ 4;  гл. 3, $\\S$ 1; Ю.Е. Нестеров Введение в выпуклую оптимизацию, $\\S$ 2.2)\n",
    "От общего к частному:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 1.** \n",
    "Пусть \n",
    "\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$, \n",
    "- градиент $f(x)$ удовлетворяет условию Липшица с константой $L$\n",
    "- $f(x)$ ограничена снизу\n",
    "- $\\alpha = const$ и $0 < \\alpha < \\frac{2}{L}$\n",
    "\n",
    "Тогда для градиентного метода выполнено:\n",
    "$$\n",
    "\\lim\\limits_{k \\to \\infty} f'(x_k) = 0,\n",
    "$$\n",
    "а функция монотонно убывает $f(x_{k+1}) < f(x_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "** Теорема 2.**\n",
    "Пусть\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$, \n",
    "- градиент $f(x)$ непрерывен\n",
    "- множество $\\{ x: f(x) \\leq f(x_0) \\}$ ограничено\n",
    "- $\\alpha_k = \\arg\\min\\limits_{\\alpha \\geq 0} f(x_k - \\alpha f'(x_k))$\n",
    "\n",
    "Тогда \n",
    "$$\n",
    "f'(x_k) \\to 0, \\; k \\to \\infty \\qquad x_{k_i} \\to x^*\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 3.** Пусть\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$\n",
    "- $f(x)$ выпукла \n",
    "- $f'(x)$ удовлетворяет условию Липшица с константой $L$\n",
    "- $\\alpha = \\dfrac{1}{L}$\n",
    "\n",
    "Тогда \n",
    "$$\n",
    "f(x_k) - f^* \\leq \\dfrac{2L \\| x_0 - x^*\\|^2_2}{k+4}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 4.** \n",
    "Пусть\n",
    "\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$, \n",
    "- градиент $f(x)$ удовлетворяет условию Липшица с константой $L$\n",
    "- $f(x)$ является сильно выпуклой с константой $l$\n",
    "- $\\alpha = const$ и $0 < \\alpha < \\frac{2}{L}$\n",
    "\n",
    "Тогда градиентный метод сходится к единственной точке глобального минимума $x^*$ с линейной скоростью:\n",
    "$$\n",
    "\\| x_k - x^* \\|_2 \\leq cq^k, \\qquad 0 \\leq q < 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 5.**\n",
    "Пусть\n",
    "\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$, \n",
    "- градиент $f(x)$ удовлетворяет условию Липшица с константой $L$\n",
    "- $f(x)$ является сильно выпуклой с константой $l$\n",
    "- $\\alpha = \\dfrac{2}{l + L}$\n",
    "\n",
    "Тогда для градиентного метода выполнено:\n",
    "$$\n",
    "\\| x_k - x^* \\|^2_2 \\leq \\left( \\dfrac{M - 1}{M + 1} \\right)^k \\|x_0 - x^*\\|^2_2 \\qquad f(x_k) - f^* \\leq \\dfrac{L}{2} \\left( \\dfrac{M - 1}{M + 1} \\right)^{2k} \\| x_0 - x^*\\|^2_2,\n",
    "$$\n",
    "где $M = \\frac{L}{l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 6.**\n",
    "Пусть \n",
    "- $f(x)$ дважды дифференцируема и $l\\mathbf{I} \\preceq f''(x) \\preceq L\\mathbf{I}$ для всех $x$\n",
    "- $\\alpha = const$ и $0 < \\alpha < \\frac{2}{L}$\n",
    "\n",
    "Тогда \n",
    "$$\n",
    "\\| x_k - x^*\\|_2 \\leq \\|x_0 - x^*\\|_2 q^k, \\qquad q = \\max(|1 - \\alpha l|, |1 - \\alpha L|) < 1\n",
    "$$\n",
    "и минимальное $q^* = \\dfrac{L - l}{L + l}$ при $\\alpha^* = \\dfrac{2}{L + l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### От чего зависит $q^*$ и как это использовать?\n",
    "Из Теорем 5 и 6 имеем \n",
    "$$\n",
    "q^* = \\dfrac{L - l}{L + l} = \\dfrac{L/l - 1}{L/l + 1} = \\dfrac{M - 1}{M + 1},\n",
    "$$\n",
    "где $M$ - оценка числа обусловленности $f''(x)$.\n",
    "\n",
    "**Вопрос**: что такое число обусловленности матрицы?\n",
    "\n",
    "- При $M \\gg 1$, $q^* \\to 1 \\Rightarrow$ оооочень **медленная** сходимости градиентного метода. Например при $M = 100$: $q^* \\approx 0.98 $\n",
    "- При $M \\simeq 1$, $q^* \\to 0 \\Rightarrow$ **ускорение** сходимости градиентного метода. Например при $M = 4$: $q^* = 0.6 $\n",
    "\n",
    "**Вопрос**: какая геометрия у этого требования?\n",
    "\n",
    "**Мораль**: необходимо сделать оценку $M$ как можно ближе к 1!\n",
    "\n",
    "О том, как это сделать, Вам будет предложено подумать в домашнем задании :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Вычислительный аспект\n",
    "1. Для каждого шага метода нужно хранить только текущую точку и вектор градиента: $O(n)$ памяти\n",
    "2. Поиск $\\alpha_k$:\n",
    "    - дан априори\n",
    "    - ищется из аналитического решения задачи наискорейшего спуска\n",
    "    - заканчивается за конечное число шагов\n",
    "3. Для каждого шага метода нужно вычислять линейную комбинацию векторов: $O(n)$ вычислений + высокопроизводительные реализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pro & Contra\n",
    "\n",
    "Pro\n",
    "- легко реализовать\n",
    "- сходимость как минимум к стационарной точке\n",
    "- параметры при выборе шага влияют на сходимость не столь сильно\n",
    "\n",
    "Contra\n",
    "- линейная сходимость\n",
    "- очень сильно зависит от числа обусловленности $f''(x)$\n",
    "- не является оптимальным для выпуклых функций с липшицевым градиентом и сильновыпуклых функций (см. [ускорение Нестерова](https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Резюме\n",
    "1. Методы спуска\n",
    "2. Направление убывания\n",
    "3. Градиентный метод\n",
    "4. Правила выбора шага\n",
    "5. Теоремы сходимости\n",
    "6. Эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1609.04747v1.pdf \n",
    "http://sebastianruder.com/optimizing-gradient-descent/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
