{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Семинар 13\n",
    "\n",
    "# Методы спуска (Descent methods). Градиентный спуск: дёшево и сердито"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## На прошлом семинаре...\n",
    "1. Введение в численные методы оптимизации\n",
    "2. Общая схема работы метода\n",
    "3. Как сравнивать методы оптимизации?\n",
    "4. Зоопарк задач и методов\n",
    "5. Одномерная минимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Что такое методы спуска?\n",
    "\n",
    "Последовательность $x_k$ генерируется по правилу\n",
    "$$\n",
    "x_{k+1} = x_k + \\alpha_k h_k\n",
    "$$\n",
    "так что\n",
    "$$\n",
    "f(x_{k+1}) < f(x_k)\n",
    "$$\n",
    "Направление $h_k$ называется *направлением убывания*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "def DescentMethod(f, x0, epsilon, **kwargs):\n",
    "    x = x0\n",
    "    while StopCriterion(x, f, **kwargs) > epsilon:\n",
    "        h = ComputeDescentDirection(x, f, **kwargs)\n",
    "        alpha = SelectStepSize(x, h, f, **kwargs)\n",
    "        x = x + alpha * h\n",
    "    return x\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Направление убывания\n",
    "Рассмотрим линейную аппроксимацию дифференцируемой функции $f$ вдоль некоторого направления убывания $h, \\|h\\|_2 = 1$:\n",
    "$$\n",
    "f(x + \\alpha h) = f(x) + \\alpha \\langle f'(x), h \\rangle + o(\\alpha)\n",
    "$$\n",
    "Из условия убывания\n",
    "$$\n",
    "f(x) + \\alpha \\langle f'(x), h \\rangle + o(\\alpha) < f(x)\n",
    "$$\n",
    "и переходя к пределу при $\\alpha \\rightarrow 0$:\n",
    "$$\n",
    "\\langle f'(x), h \\rangle \\leq 0\n",
    "$$\n",
    "Также из неравенства Коши-Буняковского-Шварца\n",
    "$$\n",
    "\\langle f'(x), h \\rangle \\geq -\\| f'(x) \\|_2 \\| h \\|_2 = -\\| f'(x) \\|_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Таким образом, направление антиградиента \n",
    "$$\n",
    "h = -\\dfrac{f'(x)}{\\|f'(x)\\|_2}\n",
    "$$\n",
    "даёт направление **наискорейшего локального** убывания функции$~f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Градиентный метод\n",
    "```python\n",
    "def GradientDescentMethod(f, x0, epsilon, **kwargs):\n",
    "    x = x0\n",
    "    while StopCriterion(x, f, **kwargs) > epsilon:\n",
    "        h = ComputeGradient(x, f, **kwargs)\n",
    "        alpha = SelectStepSize(x, h, f, **kwargs)\n",
    "        x = x - alpha * h\n",
    "    return x\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Как выбрать шаг $\\alpha_k$? (J. Nocedal, S. Wright Numerical Optimization, $\\S$ 3.1.)\n",
    "\n",
    "Список подходов:\n",
    "- Постоянный шаг \n",
    "$$\n",
    "\\alpha_k = \\overline{\\alpha}\n",
    "$$\n",
    "- Априорно заданная последовательность, например\n",
    "$$\n",
    "\\alpha_k = \\dfrac{\\overline{\\alpha}}{\\sqrt{k+1}}\n",
    "$$\n",
    "- Наискорейший спуск\n",
    "$$\n",
    "\\alpha_k = \\arg\\min_{\\alpha \\geq 0} f(x_k - \\alpha f'(x_k))\n",
    "$$\n",
    "- Требование **достаточного** убывания, требование **существенного** убывания и условие кривизны: для некоторых $\\beta_1, \\beta_2$, таких что $0 < \\beta_1 < \\beta_2 < 1$ найти $x_{k+1}$ такую что\n",
    "\n",
    "    - Достаточное убывание: $f(x_{k+1}) \\leq f(x_k) - \\beta_1 \\alpha_k \\langle f'(x_k), h_k \\rangle$\n",
    "    - Существенное убывание: $f(x_{k+1}) \\geq f(x_k) - \\beta_2 \\alpha_k \\langle f'(x_k), h_k \\rangle$\n",
    "    - Условие кривизны: $\\langle f'(x_{k+1}), h_k \\rangle \\geq \\beta_2 \\langle f'(x_k), h_k \\rangle$\n",
    "\n",
    "Обычно коэффициенты выбирают так: $\\beta_1 \\in (0, 0.1)$, а $\\beta_2 \\in (0.9, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Анализ и мотивация подходов к выбору шага $\\alpha_k$\n",
    "- Постоянный шаг: самое простое и неэффективное решение\n",
    "- Априорно заданная последовательность: немногим лучше постоянного шага\n",
    "- Наискорейший спуск: самое лучшее решение, но применимо только если вспомогательная задача решается аналитически или ооооооочень быстро. <br></br>\n",
    "То есть почти всегда неприменимо :)\n",
    "- Требование достаточного убывания, требование существенного убывания и условие кривизны:\n",
    "    - требование достаточного убывания гарантирует, что функция в точке $x_{k+1}$ не превосходит линейной аппроксимации с коэффициентом наклона $\\beta_1$\n",
    "    - требование существенного убывания гарантирует, что функция в точке $x_{k+1}$ убывает не меньше, чем линейная аппроксимация c коэффициентом наклона $\\beta_2$\n",
    "    - условие кривизны гарантирует, что угол наклона касательной в точке $x_{k+1}$ не меньше, чем угол наклона касательной в точке $x_k$, <br></br>\n",
    "умноженный на $\\beta_2$ \n",
    "\n",
    "Требование существенного убывания и условие кривизны обеспечивают убывание функции по выбранному направлению $h_k$. Обычно выбирают одно из них.\n",
    "[comment]: <> (<img src=\"Goldstein.png\", style=\"width: 600px;\">)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Альтернативные названия\n",
    "- Требование достаточного убывания $\\equiv$ правило Армихо\n",
    "- Требование достаточного убывания + условие кривизны $\\equiv$ правило Вольфа\n",
    "- Требование достаточного убывания + требование существенного убывания $\\equiv$ правило Гольдштейна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backtracking \n",
    "\n",
    "```python\n",
    "def SelectStepSize(x, f, h, rho, alpha0, beta1, beta2):\n",
    "    # 0 < rho < 1\n",
    "    # alpha0 - initial guess of step size\n",
    "    # beta1 and beta2 - constants from conditions\n",
    "    alpha = alpha0\n",
    "    # Check violoting sufficient decrease and curvature conditions \n",
    "    while (f(x - alpha * h) >= f(x) + beta1 * alpha grad_f(x_k).dot(h)) and \n",
    "          (grad_f(x - alpha * h).dot(h) <= beta2 * grad_f(x_k).dot(h)):\n",
    "        alpha *= rho\n",
    "    return alpha\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Теоремы сходимости (Б.Т. Поляк Введение в оптимизацию, гл. 1, $\\S$ 4;  гл. 3, $\\S$ 1; Ю.Е. Нестеров Введение в выпуклую оптимизацию, $\\S$ 2.2)\n",
    "От общего к частному:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 1.** \n",
    "Пусть \n",
    "\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$, \n",
    "- градиент $f(x)$ удовлетворяет условию Липшица с константой $L$\n",
    "- $f(x)$ ограничена снизу\n",
    "- $\\alpha = const$ и $0 < \\alpha < \\frac{2}{L}$\n",
    "\n",
    "Тогда для градиентного метода выполнено:\n",
    "$$\n",
    "\\lim\\limits_{k \\to \\infty} f'(x_k) = 0,\n",
    "$$\n",
    "а функция монотонно убывает $f(x_{k+1}) < f(x_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "** Теорема 2.**\n",
    "Пусть\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$, \n",
    "- градиент $f(x)$ непрерывен\n",
    "- множество $\\{ x: f(x) \\leq f(x_0) \\}$ ограничено\n",
    "- $\\alpha_k = \\arg\\min\\limits_{\\alpha \\geq 0} f(x_k - \\alpha f'(x_k))$\n",
    "\n",
    "Тогда \n",
    "$$\n",
    "f'(x_k) \\to 0, \\; k \\to \\infty \\qquad x_{k_i} \\to x^*\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 3.** Пусть\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$\n",
    "- $f(x)$ выпукла \n",
    "- $f'(x)$ удовлетворяет условию Липшица с константой $L$\n",
    "- $\\alpha = \\dfrac{1}{L}$\n",
    "\n",
    "Тогда \n",
    "$$\n",
    "f(x_k) - f^* \\leq \\dfrac{2L \\| x_0 - x^*\\|^2_2}{k+4}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 4.** \n",
    "Пусть\n",
    "\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$, \n",
    "- градиент $f(x)$ удовлетворяет условию Липшица с константой $L$\n",
    "- $f(x)$ является сильно выпуклой с константой $l$\n",
    "- $\\alpha = const$ и $0 < \\alpha < \\frac{2}{L}$\n",
    "\n",
    "Тогда градиентный метод сходится к единственной точке глобального минимума $x^*$ с линейной скоростью:\n",
    "$$\n",
    "\\| x_k - x^* \\|_2 \\leq cq^k, \\qquad 0 \\leq q < 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 5.**\n",
    "Пусть\n",
    "\n",
    "- $f(x)$ дифференцируема на $\\mathbb{R}^n$, \n",
    "- градиент $f(x)$ удовлетворяет условию Липшица с константой $L$\n",
    "- $f(x)$ является сильно выпуклой с константой $l$\n",
    "- $\\alpha = \\dfrac{2}{l + L}$\n",
    "\n",
    "Тогда для градиентного метода выполнено:\n",
    "$$\n",
    "\\| x_k - x^* \\|^2_2 \\leq \\left( \\dfrac{M - 1}{M + 1} \\right)^k \\|x_0 - x^*\\|^2_2 \\qquad f(x_k) - f^* \\leq \\dfrac{L}{2} \\left( \\dfrac{M - 1}{M + 1} \\right)^{2k} \\| x_0 - x^*\\|^2_2,\n",
    "$$\n",
    "где $M = \\frac{L}{l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Теорема 6.**\n",
    "Пусть \n",
    "- $f(x)$ дважды дифференцируема и $l\\mathbf{I} \\preceq f''(x) \\preceq L\\mathbf{I}$ для всех $x$\n",
    "- $\\alpha = const$ и $0 < \\alpha < \\frac{2}{L}$\n",
    "\n",
    "Тогда \n",
    "$$\n",
    "\\| x_k - x^*\\|_2 \\leq \\|x_0 - x^*\\|_2 q^k, \\qquad q = \\max(|1 - \\alpha l|, |1 - \\alpha L|) < 1\n",
    "$$\n",
    "и минимальное $q^* = \\dfrac{L - l}{L + l}$ при $\\alpha^* = \\dfrac{2}{L + l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### От чего зависит $q^*$ и как это использовать?\n",
    "Из Теорем 5 и 6 имеем \n",
    "$$\n",
    "q^* = \\dfrac{L - l}{L + l} = \\dfrac{L/l - 1}{L/l + 1} = \\dfrac{M - 1}{M + 1},\n",
    "$$\n",
    "где $M$ - оценка числа обусловленности $f''(x)$.\n",
    "\n",
    "**Вопрос**: что такое число обусловленности матрицы?\n",
    "\n",
    "- При $M \\gg 1$, $q^* \\to 1 \\Rightarrow$ оооочень **медленная** сходимости градиентного метода. Например при $M = 100$: $q^* \\approx 0.98 $\n",
    "- При $M \\simeq 1$, $q^* \\to 0 \\Rightarrow$ **ускорение** сходимости градиентного метода. Например при $M = 4$: $q^* = 0.6 $\n",
    "\n",
    "**Вопрос**: какая геометрия у этого требования?\n",
    "\n",
    "**Мораль**: необходимо сделать оценку $M$ как можно ближе к 1!\n",
    "\n",
    "О том, как это сделать, Вам будет предложено подумать в домашнем задании :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Вычислительный аспект и эксперименты\n",
    "1. Для каждого шага метода нужно хранить только текущую точку и вектор градиента: $O(n)$ памяти\n",
    "2. Поиск $\\alpha_k$:\n",
    "    - дан априори\n",
    "    - ищется из аналитического решения задачи наискорейшего спуска\n",
    "    - заканчивается за конечное число шагов\n",
    "3. Для каждого шага метода нужно вычислять линейную комбинацию векторов: $O(n)$ вычислений + высокопроизводительные реализации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pеализация градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def GradientDescent(f, gradf, x0, epsilon, num_iter, line_search, \n",
    "                    disp=False, callback=None, **kwargs):\n",
    "    x = x0.copy()\n",
    "    iteration = 0\n",
    "    opt_arg = {\"f\": f, \"grad_f\": gradf}\n",
    "    for key in kwargs:\n",
    "        opt_arg[key] = kwargs[key]\n",
    "    while True:\n",
    "        gradient = gradf(x)\n",
    "        alpha = line_search(x, gradient, **opt_arg)\n",
    "        x = x - alpha * gradient\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "        iteration += 1\n",
    "        if disp:\n",
    "            print \"Current function val =\", f(x)\n",
    "            print \"Current gradient norm = \", np.linalg.norm(gradf(x))\n",
    "        if np.linalg.norm(gradf(x)) < epsilon:\n",
    "            break\n",
    "        if iteration >= num_iter:\n",
    "            break\n",
    "    res = {\"x\": x, \"num_iter\": iteration, \"tol\": np.linalg.norm(gradf(x))}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Выбор шага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def constant_step(x, gradient, **kwargs):\n",
    "    return 1e-3\n",
    "\n",
    "# For quadratic function x'Ax\n",
    "def exact_linesearch(x, gradient, **kwargs):\n",
    "    return max(0, x.dot(A.dot(gradient)) / gradient.dot(A.dot(gradient)))\n",
    "\n",
    "def backtracking(x, gradient, **kwargs):\n",
    "    f = kwargs[\"f\"]\n",
    "    grad_f = kwargs[\"grad_f\"] \n",
    "    if kwargs[\"method\"] == \"Armijo\":\n",
    "        beta1 = kwargs[\"beta1\"]\n",
    "        rho = kwargs[\"rho\"]\n",
    "        alpha = 1\n",
    "        while f(x - alpha * gradient) >= f(x) - beta1 * alpha * grad_f(x).dot(gradient) or \\\n",
    "                 np.isnan(f(x - alpha * gradient)):\n",
    "            alpha *= rho\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Зависимость от обусловленности матрицы $f''(x)$\n",
    "Рассмотрим задачу \n",
    "$$\n",
    "\\min f(x),\n",
    "$$ \n",
    "где\n",
    "$$\n",
    "f(x) = x^{\\top}Ax, \\; A = \n",
    "\\begin{bmatrix}\n",
    "1 & 0\\\\\n",
    "0 & \\gamma\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f'(x) = 2Ax\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def my_f(x, A):\n",
    "    return x.dot(A.dot(x))\n",
    "\n",
    "def my_gradf(x, A):\n",
    "    return 2 * A.dot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a54e2cb900a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgammas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_iter_converg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/envs/cvxpy/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/envs/cvxpy/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-104>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/envs/cvxpy/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/envs/cvxpy/lib/python2.7/site-packages/IPython/core/magics/pylab.pyc\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/envs/cvxpy/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   2933\u001b[0m         \"\"\"\n\u001b[1;32m   2934\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2935\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/envs/cvxpy/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \"\"\"\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named matplotlib"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gammas = [0.1, 0.5, 1, 2, 3, 4, 5, 10, 20, 50, 100, 1000, 5000, 10000]\n",
    "num_iter_converg = []\n",
    "for g in gammas:\n",
    "    A = np.array([[1, 0], \n",
    "                  [0, g]], dtype=np.float64)\n",
    "    f = lambda x: my_f(x, A)\n",
    "    gradf = lambda x: my_gradf(x, A)\n",
    "#     x0 = np.random.rand(A.shape[0])\n",
    "#     x0 = np.sort(x0)\n",
    "#     x0 = x0[::-1]\n",
    "    x0 = np.array([g, 1], dtype=np.float64)\n",
    "#     print x0[1] / x0[0]\n",
    "    res = GradientDescent(f, gradf, x0, 1e-7, 10000, exact_linesearch)\n",
    "    num_iter_converg.append(res[\"num_iter\"])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.loglog(gammas, num_iter_converg)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xlabel(r\"$\\gamma$\", fontsize=20)\n",
    "plt.ylabel(r\"Number of iteration with $\\varepsilon = 10^{-7}$\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Эксперимент на многомерной задаче\n",
    "Пусть $A \\in \\mathbb{R}^{m \\times n}$. Рассмотрим систему линейных неравенств: $Ax \\leq 1$ при условии $|x_i| \\leq 1$ для всех $i$.\n",
    "\n",
    "**Определение.** Аналитическим центром системы неравенств $Ax \\leq 1$ при условии $|x_i| \\leq 1$ является решение задачи\n",
    "$$\n",
    "f(x) = - \\sum_{i=1}^m \\log(1 - a_i^{\\top}x) - \\sum\\limits_{i = 1}^n \\log (1 - x^2_i)\n",
    "$$\n",
    "$$\n",
    "f'(x) - ?\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "m = 200\n",
    "x0 = np.zeros((n,))\n",
    "A = np.random.rand(n, m) * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Точное решение с помощью CVXPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "print cvx.installed_solvers()\n",
    "x = cvx.Variable(n, 1)\n",
    "\n",
    "obj = cvx.Minimize(cvx.sum_entries(-cvx.log(1 - A.T * x)) - \n",
    "                   cvx.sum_entries(cvx.log(1 - cvx.square(x))))\n",
    "prob = cvx.Problem(obj)\n",
    "prob.solve(solver=\"ECOS\", verbose=False)\n",
    "x = x.value\n",
    "print \"Optimal value =\", prob.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Решение с помощью градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f = lambda x: -np.sum(np.log(1 - A.T.dot(x))) - np.sum(np.log(1 - x*x))\n",
    "grad_f = lambda x: np.sum(A.dot(np.diagflat(1 / (1 - A.T.dot(x)))), axis=1) + 2 * x / (1 - np.power(x, 2))\n",
    "def my_callback(x, array):\n",
    "    array.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "res = GradientDescent(f, grad_f, x0, 1e-4, 100, backtracking, \n",
    "                        method=\"Armijo\", beta1=0.1, rho=0.7)\n",
    "print \"Gradient norm {} and optimal value = {}\".format(\n",
    "    np.linalg.norm(grad_f(res[\"x\"])), f(res[\"x\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Зависимость скорости сходимости от параметров линейного поиска\n",
    "\n",
    "Для простоты используем только условие достаточного убывания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Зависимость от $\\rho$\n",
    "\n",
    "От величины коэффициента $\\rho$ зависит насколько агрессивно будет уменьшаться величина шага в процессе поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rhos = [0.7 + i * 0.05 for i in xrange(5)]\n",
    "hist_x = []\n",
    "callback = lambda x: my_callback(x, hist_x)\n",
    "plt.figure(figsize=(8, 5))\n",
    "for rho in rhos:\n",
    "    GradientDescent(f, grad_f, x0, 1e-4, 100, backtracking, callback=callback, \n",
    "                    method=\"Armijo\", beta1=0.1, rho=rho)\n",
    "    grad_norm = [np.linalg.norm(grad_f(x)) for x in hist_x]\n",
    "    plt.semilogy(range(1, len(grad_norm) + 1), grad_norm, label=r\"$\\rho$ = \" + str(rho))\n",
    "    hist_x = []\n",
    "plt.xlabel(r\"Number of iteration, $k$\", fontsize=20)\n",
    "plt.ylabel(r\"Norm of gradient, $\\| f'(x_k) \\|_2$\", fontsize=20)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.legend(loc=\"best\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Зависимость от $\\beta_1$\n",
    "\n",
    "От коэффициента $\\beta_1$ зависит угол наклона линейной аппроксимации, с которой сравнивается значение в новой точке $x_k - \\alpha_k f'(x_k)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "betas = [0.0 + i * 0.05 for i in xrange(7)]\n",
    "hist_x = []\n",
    "callback = lambda x: my_callback(x, hist_x)\n",
    "plt.figure(figsize=(8, 5))\n",
    "for beta in betas:\n",
    "    GradientDescent(f, grad_f, x0, 1e-4, 100, backtracking, callback=callback, \n",
    "                    method=\"Armijo\", beta1=beta, rho=0.7)\n",
    "    grad_norm = [np.linalg.norm(grad_f(x)) for x in hist_x]\n",
    "    plt.semilogy(range(1, len(grad_norm) + 1), grad_norm, label=r\"$\\beta_1$ = \" + str(beta))\n",
    "    hist_x = []\n",
    "plt.xlabel(r\"Number of iteration, $k$\", fontsize=20)\n",
    "plt.ylabel(r\"Norm of gradient, $\\| f'(x_k) \\|_2$\", fontsize=20)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.legend(loc=\"best\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pro & Contra\n",
    "\n",
    "Pro\n",
    "- легко реализовать\n",
    "- сходимость как минимум к стационарной точке\n",
    "- параметры при выборе шага влияют на сходимость не столь сильно\n",
    "- имеет многочисленные вариации\n",
    "\n",
    "Contra\n",
    "- линейная сходимость\n",
    "- очень сильно зависит от числа обусловленности $f''(x)$, выбор начального приближения может помочь\n",
    "- не является оптимальным для выпуклых функций с липшицевым градиентом и сильновыпуклых функций (см. [ускорение Нестерова](https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/))\n",
    "\n",
    "Возможно, расширениям и вариациям градентного спуска будет посвящён отдельный семинар."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Резюме\n",
    "1. Методы спуска\n",
    "2. Направление убывания\n",
    "3. Градиентный метод\n",
    "4. Правила выбора шага\n",
    "5. Теоремы сходимости\n",
    "6. Эксперименты"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cvxpy]",
   "language": "python",
   "name": "conda-env-cvxpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
